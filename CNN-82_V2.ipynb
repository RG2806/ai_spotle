{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMx5kI7/ea9Yf8TuyjwgyGr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RG2806/ai_spotle/blob/master/CNN-82_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjDbsTkqmK_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "390cde2c-a905-484a-8a73-6e0ae4424fa8"
      },
      "source": [
        "!git clone https://github.com/RG2806/ai_spotle.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ai_spotle'...\n",
            "remote: Enumerating objects: 4063, done.\u001b[K\n",
            "remote: Counting objects: 100% (4063/4063), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4059/4059), done.\u001b[K\n",
            "remote: Total 4063 (delta 20), reused 4032 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (4063/4063), 34.72 MiB | 9.55 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n",
            "Checking out files: 100% (4053/4053), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJiFijB7mQyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential #Initialise our neural network model as a sequential network\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation#Applies activation function\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import pandas as pd\n",
        "import keras \n",
        "from keras.layers import Conv2D, BatchNormalization, GlobalAveragePooling2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from keras.utils import np_utils\n",
        "import keras.backend as k\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "import os\n",
        "import keras\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "The following function will be called to train and test your model.\n",
        "The function name, signature and output type is fixed.\n",
        "The first argument is file name that contain data for training.\n",
        "The second argument is file name that contain data for test.\n",
        "The function must return predicted values or emotion for each data in test dataset\n",
        "sequentially in a list.\n",
        "['sad', 'happy', 'fear', 'fear', ... , 'happy']\n",
        "'''\n",
        "\n",
        "def  aithon_level2_api(trainingcsv, testcsv):\n",
        "    classes = ['Fear','Sad','Happy']\n",
        "    data = []\n",
        "    labels =[]\n",
        "    df=pd.read_csv(trainingcsv)\n",
        "    for i,row in df.iterrows():\n",
        "            image_data=np.asarray([int(x) for x in row[1:]]).reshape(48,48)\n",
        "            image_data =image_data.astype(np.float32)/255.0\n",
        "            data.append(image_data)\n",
        "            labels.append(classes.index(row[0]))\n",
        "            data.append(cv2.flip(image_data, 1))\n",
        "            labels.append(classes.index(row[0]))\n",
        "    data = np.expand_dims(data, -1)   \n",
        "    labels = to_categorical(labels, num_classes = 3)\n",
        "    train_data=np.array(data)\n",
        "    train_labels=np.array(labels)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.2, random_state=101,shuffle=True)\n",
        "    num_features = 64\n",
        "    width, height = 48, 48\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(2*2*2*num_features, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(2*2*num_features, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(2*num_features, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),metrics=['accuracy'])\n",
        "\n",
        "    lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)\n",
        "    checkpointer = ModelCheckpoint('model.h5', monitor='val_accuracy', verbose=1, save_best_only=True,mode='max')\n",
        "    callbacks = [lr_reducer, checkpointer]\n",
        "    bs = 64\n",
        "    epochs = 100\n",
        "\n",
        "    aug = ImageDataGenerator(rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, fill_mode=\"nearest\")\n",
        "\n",
        "    H = model.fit(aug.flow(x_train, y_train, batch_size=bs), validation_data=(x_test, y_test), steps_per_epoch=len(x_train)//bs, callbacks=callbacks, shuffle=True, epochs=epochs)\n",
        "    model.load_weights('/content/model.h5')\n",
        "    test_data = []\n",
        "    df1=pd.read_csv(testcsv)\n",
        "    if 'emotion' in df1.columns:\n",
        "          df1=df1.drop(['emotion'], axis = 1) \n",
        "    for i,row in df1.iterrows():\n",
        "            image_data=np.asarray([int(x) for x in row[0:]]).reshape(48,48)\n",
        "            image_data =image_data.astype(np.float32)/255.0\n",
        "            test_data.append(image_data)\n",
        "    test_data = np.expand_dims(test_data, -1)   \n",
        "    test_data=np.array(test_data)\n",
        "    y_pred=model.predict(test_data)\n",
        "    y_pred=y_pred.argmax(axis=1)\n",
        "    result=[]\n",
        "    for i in y_pred:\n",
        "      result.append(classes[i])\n",
        "    return result"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qCrC2LOnJQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list1=[]\n",
        "list1=aithon_level2_api(\"/content/ai_spotle/aithon2020_level2_traning.csv\", \"/content/ai_spotle/aithon2020_level2_traning.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SQN16jEnqWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f076f101-8225-4ba8-bed9-28825cb3cb22"
      },
      "source": [
        "df1=pd.read_csv(\"/content/ai_spotle/aithon2020_level2_traning.csv\")\n",
        "c=0\n",
        "for i,row in df1.iterrows():\n",
        "    if(row[0]==list1[i]): \n",
        "      c=c+1\n",
        "print(c/len(list1))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9179994453175557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiw2WfRO-npb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}